{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-11-27T07:14:43.814402Z",
     "iopub.status.busy": "2025-11-27T07:14:43.814017Z",
     "iopub.status.idle": "2025-11-27T07:14:59.502497Z",
     "shell.execute_reply": "2025-11-27T07:14:59.501832Z",
     "shell.execute_reply.started": "2025-11-27T07:14:43.814378Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:14:59.504476Z",
     "iopub.status.busy": "2025-11-27T07:14:59.503916Z",
     "iopub.status.idle": "2025-11-27T07:14:59.509887Z",
     "shell.execute_reply": "2025-11-27T07:14:59.509244Z",
     "shell.execute_reply.started": "2025-11-27T07:14:59.504454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/kaggle/input/chest-xray-pneumonia/chest_xray\"  # Kaggle path\n",
    "# or path to dataset locally\n",
    "\n",
    "batch_size = 32\n",
    "img_size = 224   # for ResNet\n",
    "num_workers = 4  # reduce if on CPU only\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:14:59.511231Z",
     "iopub.status.busy": "2025-11-27T07:14:59.510673Z",
     "iopub.status.idle": "2025-11-27T07:14:59.561767Z",
     "shell.execute_reply": "2025-11-27T07:14:59.561234Z",
     "shell.execute_reply.started": "2025-11-27T07:14:59.511203Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir   = os.path.join(data_dir, \"val\")\n",
    "test_dir  = os.path.join(data_dir, \"test\")\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset   = datasets.ImageFolder(val_dir,   transform=val_test_transforms)\n",
    "test_dataset  = datasets.ImageFolder(test_dir,  transform=val_test_transforms)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "print(\"Classes:\", class_names)  # ['NORMAL', 'PNEUMONIA']\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=num_workers)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=num_workers)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:32:14.076547Z",
     "iopub.status.busy": "2025-11-27T07:32:14.076206Z",
     "iopub.status.idle": "2025-11-27T07:32:14.306403Z",
     "shell.execute_reply": "2025-11-27T07:32:14.305611Z",
     "shell.execute_reply.started": "2025-11-27T07:32:14.076520Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# freeze backbone initially (optional)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# replace final layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)  # 2 classes\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:32:33.405837Z",
     "iopub.status.busy": "2025-11-27T07:32:33.405115Z",
     "iopub.status.idle": "2025-11-27T07:32:33.411389Z",
     "shell.execute_reply": "2025-11-27T07:32:33.410772Z",
     "shell.execute_reply.started": "2025-11-27T07:32:33.405808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# only train final layer at first\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                 factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:32:58.606040Z",
     "iopub.status.busy": "2025-11-27T07:32:58.605747Z",
     "iopub.status.idle": "2025-11-27T07:39:55.775116Z",
     "shell.execute_reply": "2025-11-27T07:39:55.774246Z",
     "shell.execute_reply.started": "2025-11-27T07:32:58.606018Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Train loss: 0.3253, acc: 0.8604 | Val loss: 0.3447, acc: 0.8125\n",
      "Epoch 2/10 Train loss: 0.1962, acc: 0.9241 | Val loss: 0.5006, acc: 0.7500\n",
      "Epoch 3/10 Train loss: 0.1733, acc: 0.9316 | Val loss: 0.2235, acc: 0.9375\n",
      "Epoch 4/10 Train loss: 0.1604, acc: 0.9337 | Val loss: 0.3588, acc: 0.7500\n",
      "Epoch 5/10 Train loss: 0.1544, acc: 0.9367 | Val loss: 0.3226, acc: 0.7500\n",
      "Epoch 6/10 Train loss: 0.1431, acc: 0.9475 | Val loss: 0.4203, acc: 0.7500\n",
      "Epoch 7/10 Train loss: 0.1428, acc: 0.9431 | Val loss: 0.4971, acc: 0.6875\n",
      "Epoch 8/10 Train loss: 0.1341, acc: 0.9477 | Val loss: 0.4314, acc: 0.7500\n",
      "Epoch 9/10 Train loss: 0.1255, acc: 0.9509 | Val loss: 0.4165, acc: 0.7500\n",
      "Epoch 10/10 Train loss: 0.1274, acc: 0.9498 | Val loss: 0.3282, acc: 0.7500\n",
      "Best val acc: 0.9375\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
    "                num_epochs=10):\n",
    "    best_val_acc = 0.0\n",
    "    best_state_dict = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_corrects.double() / len(val_loader.dataset)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "              f\"Train loss: {epoch_loss:.4f}, acc: {epoch_acc:.4f} | \"\n",
    "              f\"Val loss: {val_loss:.4f}, acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state_dict = model.state_dict()\n",
    "\n",
    "    if best_state_dict is not None:\n",
    "        model.load_state_dict(best_state_dict)\n",
    "\n",
    "    print(\"Best val acc:\", best_val_acc.item())\n",
    "    return model\n",
    "\n",
    "model = train_model(model, train_loader, val_loader, criterion, optimizer,\n",
    "                    scheduler, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:40:35.675835Z",
     "iopub.status.busy": "2025-11-27T07:40:35.675504Z",
     "iopub.status.idle": "2025-11-27T07:40:40.133564Z",
     "shell.execute_reply": "2025-11-27T07:40:40.132653Z",
     "shell.execute_reply.started": "2025-11-27T07:40:35.675807Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.94      0.71      0.81       234\n",
      "   PNEUMONIA       0.85      0.97      0.91       390\n",
      "\n",
      "    accuracy                           0.88       624\n",
      "   macro avg       0.89      0.84      0.86       624\n",
      "weighted avg       0.88      0.88      0.87       624\n",
      "\n",
      "Confusion matrix:\n",
      "[[167  67]\n",
      " [ 11 379]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(all_labels, all_preds,\n",
    "                            target_names=class_names))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
